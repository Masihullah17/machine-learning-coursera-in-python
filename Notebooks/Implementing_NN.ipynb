{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementing_NN.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "tz4Z93RjcMr_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from scipy.io import loadmat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MI0QFrNxdF7a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mat2=loadmat(\"ex4data1.mat\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5v8KPNWdPt9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = mat2[\"X\"]\n",
        "y = mat2[\"y\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sax78JW9dnbc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoid(z):\n",
        "  return 1 / (1 + np.exp(-z))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QfmN-rUvffMH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def sigmoidGradient(z):\n",
        "  sigmoid = 1 / (1 + np.exp(-z))\n",
        "  return sigmoid * (1 - sigmoid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8eCNwTKeHel",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels,X, y,Lambda):\n",
        "    # Reshape nn_params back into the parameters Theta1 and Theta2\n",
        "    Theta1 = nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
        "    Theta2 = nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
        "    \n",
        "    m = X.shape[0]\n",
        "    J=0\n",
        "    X = np.hstack((np.ones((m,1)),X))\n",
        "    y10 = np.zeros((m,num_labels))\n",
        "    \n",
        "    a1 = sigmoid(X @ Theta1.T)\n",
        "    a1 = np.hstack((np.ones((m,1)), a1)) # hidden layer\n",
        "    a2 = sigmoid(a1 @ Theta2.T) # output layer\n",
        "    \n",
        "    for i in range(1,num_labels+1):\n",
        "        y10[:,i-1][:,np.newaxis] = np.where(y==i,1,0)\n",
        "    for j in range(num_labels):\n",
        "        J = J + sum(-y10[:,j] * np.log(a2[:,j]) - (1-y10[:,j])*np.log(1-a2[:,j]))\n",
        "    \n",
        "    cost = 1/m* J\n",
        "    reg_J = cost + Lambda/(2*m) * (np.sum(Theta1[:,1:]**2) + np.sum(Theta2[:,1:]**2))\n",
        "    \n",
        "    # Implement the backpropagation algorithm to compute the gradients\n",
        "    \n",
        "    grad1 = np.zeros((Theta1.shape))\n",
        "    grad2 = np.zeros((Theta2.shape))\n",
        "    \n",
        "    for i in range(m):\n",
        "        xi= X[i,:] # 1 X 401\n",
        "        a1i = a1[i,:] # 1 X 26\n",
        "        a2i =a2[i,:] # 1 X 10\n",
        "        d2 = a2i - y10[i,:]\n",
        "        d1 = Theta2.T @ d2.T * sigmoidGradient(np.hstack((1,xi @ Theta1.T)))\n",
        "        grad1= grad1 + d1[1:][:,np.newaxis] @ xi[:,np.newaxis].T\n",
        "        grad2 = grad2 + d2.T[:,np.newaxis] @ a1i[:,np.newaxis].T\n",
        "        \n",
        "    grad1 = 1/m * grad1\n",
        "    grad2 = 1/m*grad2\n",
        "    \n",
        "    grad1_reg = grad1 + (Lambda/m) * np.hstack((np.zeros((Theta1.shape[0],1)),Theta1[:,1:]))\n",
        "    grad2_reg = grad2 + (Lambda/m) * np.hstack((np.zeros((Theta2.shape[0],1)),Theta2[:,1:]))\n",
        "    \n",
        "    return cost, grad1, grad2,reg_J, grad1_reg,grad2_reg"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mjKlUPgsfACV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8491e8bd-870a-47a0-ca13-7b68f6b491e6"
      },
      "cell_type": "code",
      "source": [
        "input_layer_size  = 400\n",
        "hidden_layer_size = 25\n",
        "num_labels = 10\n",
        "nn_params = np.append(Theta1.flatten(),Theta2.flatten())\n",
        "J,reg_J = nnCostFunction(nn_params, input_layer_size, hidden_layer_size, num_labels, X, y, 1)[0:4:3]\n",
        "print(\"Cost at parameters (non-regularized):\",J,\"\\nCost at parameters (Regularized):\",reg_J)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost at parameters (non-regularized): 0.28762916516131876 \n",
            "Cost at parameters (Regularized): 0.3837698590909235\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BL_9JQXKfWiT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def randInitializeWeights(L_in, L_out):\n",
        "    epi = (6**1/2) / (L_in + L_out)**1/2\n",
        "    \n",
        "    W = np.random.rand(L_out,L_in +1) *(2*epi) -epi\n",
        "    \n",
        "    return W"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nJjiuqBRgItx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "initial_Theta1 = randInitializeWeights(input_layer_size, hidden_layer_size)\n",
        "initial_Theta2 = randInitializeWeights(hidden_layer_size, num_labels)\n",
        "initial_nn_params = np.append(initial_Theta1.flatten(),initial_Theta2.flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gfQV5jyqgOGG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def gradientDescentnn(X,y,initial_nn_params,alpha,num_iters,Lambda,input_layer_size, hidden_layer_size, num_labels):\n",
        "    Theta1 = initial_nn_params[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
        "    Theta2 = initial_nn_params[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)\n",
        "    \n",
        "    m=len(y)\n",
        "    J_history =[]\n",
        "    \n",
        "    for i in range(num_iters):\n",
        "        nn_params = np.append(Theta1.flatten(),Theta2.flatten())\n",
        "        cost, grad1, grad2 = nnCostFunction(nn_params,input_layer_size, hidden_layer_size, num_labels,X, y,Lambda)[3:]\n",
        "        Theta1 = Theta1 - (alpha * grad1)\n",
        "        Theta2 = Theta2 - (alpha * grad2)\n",
        "        J_history.append(cost)\n",
        "    \n",
        "    nn_paramsFinal = np.append(Theta1.flatten(),Theta2.flatten())\n",
        "    return nn_paramsFinal , J_history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mmkRU7rYgpli",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "alpha = 0.8\n",
        "num_iters = 800\n",
        "Lambda = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vlr4h5ZEgyx2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "nnTheta, nnJ_history = gradientDescentnn(X,y,initial_nn_params,alpha,num_iters,Lambda,input_layer_size, hidden_layer_size, num_labels)\n",
        "Theta1 = nnTheta[:((input_layer_size+1) * hidden_layer_size)].reshape(hidden_layer_size,input_layer_size+1)\n",
        "Theta2 = nnTheta[((input_layer_size +1)* hidden_layer_size ):].reshape(num_labels,hidden_layer_size+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q6Ralym9jTLR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict(Theta1, Theta2, X):\n",
        "    m= X.shape[0]\n",
        "    X = np.hstack((np.ones((m,1)),X))\n",
        "    \n",
        "    a1 = sigmoid(X @ Theta1.T)\n",
        "    a1 = np.hstack((np.ones((m,1)), a1)) # hidden layer\n",
        "    a2 = sigmoid(a1 @ Theta2.T) # output layer\n",
        "    \n",
        "    return np.argmax(a2,axis=1)+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lqgGirQ4g-eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8b5ad4c-4a83-43cc-8746-397e95af9d3c"
      },
      "cell_type": "code",
      "source": [
        "pred3 = predict(Theta1, Theta2, X)\n",
        "print(\"Training Set Accuracy:\",sum(pred3[:,np.newaxis]==y)[0]/5000*100,\"%\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Accuracy: 93.86 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uz4-pWVPizMu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}